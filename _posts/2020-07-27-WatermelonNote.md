---
layout: blogpage
title: 吃西瓜书
comments: true
tags: Note Machine-Learning
---
## Chapter 1 &nbsp;&nbsp;绪论 ##


- 聚类 · 把训练集中的数据分成若干组，每组叫一个簇(cluster)；这些自动形成的簇可能对应一些潜在的概念划分，如“浅色瓜/深色瓜”。
- 根据训练数据是否有标记信息，学习任务被分为监督学习和无监督学习
- 概念学习研究太少了。因为要学得泛化性能好且语义明确的概念太困难了，现实中常用的大多数是产生黑箱模型。
-  机器学习算法在学习过程中对某种类型假设的偏好称为偏好或归纳偏好(inductive bias)。


-  奥卡姆剃刀(Occam's razor) · 若有多个假设与观察一致，选择最简单的那个。自然认为平滑曲线更简单（更易于描述）。


但奥卡姆剃刀并非唯一可行原则，有时无法判断两种假设谁更简单。

奥卡姆剃刀也并非科学研究中唯一可行的假设选择原则，例如古希腊哲学家伊壁鸠鲁的多释原则(principle of multiple explanations)，主张保留与经验观察一致的所有假设，这与集成学习(ensemble learning)方面的研究更加吻合。


-  对任意一个学习算法A1，若在某些问题上比学习算法A2好，则必有另一些问题A2效果比A1好。
-  没有免费的午餐定理(No Free Lunch Theorem, NFL) · 所有问题出现机会相同/所有问题同等重要时，无论学习算法如何，他们的期望性能相同/总误差相同。


现实中只关注试图解决的具体问题，所以不适用。学习算法的优劣脱离具体问题毫无意义，其自身归纳偏好与问题是否相配往往起到决定性作用。


-  深度学习技术涉及到的模型复杂度高，以至于下功夫调参，把参数调节好，性能往往就好。
-  神经网络在二十世纪八十年代中期和深度学习在二十一世纪初的走红都和计算能力、存储效率的显著提高相关联。



## Chapter 2 &nbsp;&nbsp;模型评估与选择 ##  
